[{"fullname": "pybann", "modulename": "pybann", "qualname": "", "type": "module", "doc": "<p>PyBANN is a Python Basic Artificial Neural Network.</p>\n"}, {"fullname": "pybann.activation", "modulename": "pybann.activation", "qualname": "", "type": "module", "doc": "<p>activation.py</p>\n"}, {"fullname": "pybann.activation.Activation", "modulename": "pybann.activation", "qualname": "Activation", "type": "class", "doc": "<p>Collection of activation functions commonly used in the design of\nartificial neural networks.</p>\n\n<p>An activation function, in artificial neural networks, defines how the weighted sum\nof the input is transformed into an output.</p>\n\n<p>All methods are statics which means they can be called without creating an instance.</p>\n"}, {"fullname": "pybann.activation.Activation.__init__", "modulename": "pybann.activation", "qualname": "Activation.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.activation.Activation.sigmoid", "modulename": "pybann.activation", "qualname": "Activation.sigmoid", "type": "function", "doc": "<p>sigmoid</p>\n\n<p>Apply the sigmoid activation functions or its derivative to the input values.</p>\n\n<p>The sigmoid activation function returns near 0 values for input values &lt;-5 and\nnear 1 for input values &gt;5</p>\n\n<p>The sigmoid derivative is a zero-centered Gaussian-like function returning values\nbetween 0 and 0.25.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>wsum</strong> (float or numpy array):\ninput value(s)</li>\n<li><strong>deriv: bool, default</strong> (False):\nwhen <code>True</code>, returns the derivative</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>result</strong> (float or np.array):\nthe value of the function (or its derivative).</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"mf\">0.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"go\">0.5</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sigmoid</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"go\">array([0.26894142, 0.5, 0.73105858])</span>\n</code></pre></div>\n", "parameters": ["wsum", "deriv"], "funcdef": "def"}, {"fullname": "pybann.activation.Activation.tanhyp", "modulename": "pybann.activation", "qualname": "Activation.tanhyp", "type": "function", "doc": "<p>Returns the value of the Hyperbolic tangent function\n(or its derivative).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>wsum</strong> (float or numpy array):\ninput value(s)</li>\n<li><strong>deriv: bool, default</strong> (False):\nwhen <code>True</code>, returns the derivative</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>result</strong> (float or np.array):\nthe value of the function (or its derivative).</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"mf\">0.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tanhyp</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">0.</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tanhyp</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">array([-0.76159415, 0.0, 0.76159415])</span>\n</code></pre></div>\n", "parameters": ["wsum", "deriv"], "funcdef": "def"}, {"fullname": "pybann.activation.Activation.relu", "modulename": "pybann.activation", "qualname": "Activation.relu", "type": "function", "doc": "<p>Returns the value of the Rectified Linear Unit function\n(or its derivative).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>wsum</strong> (float or numpy array):\ninput value(s)</li>\n<li><strong>deriv: bool, default</strong> (False):\nwhen <code>True</code>, returns the derivative</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>result</strong> (float or np.array):\nthe value of the function (or its derivative).</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"mf\">0.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">0.</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">2.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">array([0., 0., 2.])</span>\n</code></pre></div>\n", "parameters": ["wsum", "leak", "deriv"], "funcdef": "def"}, {"fullname": "pybann.activation.Activation.softplus", "modulename": "pybann.activation", "qualname": "Activation.softplus", "type": "function", "doc": "<p>Returns the value of the Softplus function (or its derivative).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>wsum</strong> (float or numpy array):\ninput value(s)</li>\n<li><strong>deriv: bool, default</strong> (False):\nwhen <code>True</code>, returns the derivative</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>result</strong> (float or np.array):\nthe value of the function (or its derivative).</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"mf\">0.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">softplus</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">0.69314718</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">softplus</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">array([0.31326168, 0.69314718, 1.31326168])</span>\n</code></pre></div>\n", "parameters": ["wsum", "deriv"], "funcdef": "def"}, {"fullname": "pybann.activation.Activation.gaussian", "modulename": "pybann.activation", "qualname": "Activation.gaussian", "type": "function", "doc": "<p>Returns the value of the Gaussian function (or its derivative).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>wsum</strong> (float or numpy array):\ninput value(s)</li>\n<li><strong>deriv: bool, default</strong> (False):\nwhen <code>True</code>, returns the derivative</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>result</strong> (float or np.array):\nthe value of the function (or its derivative).</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"mf\">0.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">gaussian</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">1.</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">gaussian</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"go\">array([0.36787944, 1.00000000, 0.36787944])</span>\n</code></pre></div>\n", "parameters": ["wsum", "deriv"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent", "modulename": "pybann.gradientdescent", "qualname": "", "type": "module", "doc": "<p>gradientdescent.py</p>\n"}, {"fullname": "pybann.gradientdescent.GradientDescent", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent", "type": "class", "doc": "<p>Class to train the neural network using the gradient descent\nmethod.</p>\n"}, {"fullname": "pybann.gradientdescent.GradientDescent.__init__", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "dataset", "batchsize", "alpha", "nepoch", "momentum", "layers"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.init_update", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.init_update", "type": "function", "doc": "<p>Initialize weights and biases update array to zero</p>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.datasplit", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.datasplit", "type": "function", "doc": "<p>Split the data in input and output array</p>\n", "parameters": ["self", "dataset"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.forward", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.forward", "type": "function", "doc": "<p>Return the output of the neural network for a given\ninput dataset and stores the intermediate results\n(transfer and activation results).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>invalues</strong> (np.array):\nvector containing the input values for the neural network model</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>activation</strong> (np.array):\nactivation value for each node</li>\n<li><strong>transfer</strong> (np.array):\ntransfer value for each node</li>\n</ul>\n", "parameters": ["self", "invalues"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.backward", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.backward", "type": "function", "doc": "<p>Calculates the gradient for each weight matrix and biase vector\nof the neural network.</p>\n", "parameters": ["self", "activation", "transfer", "outvalues"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.update", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.update", "type": "function", "doc": "<p>Update the weight matrix and biase vector of the neural network.</p>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.gradientdescent.GradientDescent.run", "modulename": "pybann.gradientdescent", "qualname": "GradientDescent.run", "type": "function", "doc": "<p>Train</p>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.layers", "modulename": "pybann.layers", "qualname": "", "type": "module", "doc": "<p>layers.py</p>\n"}, {"fullname": "pybann.layers.Layer", "modulename": "pybann.layers", "qualname": "Layer", "type": "class", "doc": "<p>Layer class allows to add layers to the neural network model.</p>\n"}, {"fullname": "pybann.layers.Layer.__init__", "modulename": "pybann.layers", "qualname": "Layer.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "neurons", "label"], "funcdef": "def"}, {"fullname": "pybann.layers.Layer.add_activation", "modulename": "pybann.layers", "qualname": "Layer.add_activation", "type": "function", "doc": "<p>Add an activation function to the Layer object</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>activation</strong> (str (optional)):\nname of the activation function (default <code>sigmoid</code>)</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Layer</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"n\">Layer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">add_activation</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"o\">.</span><span class=\"vm\">__name__</span>\n<span class=\"go\">sigmoid</span>\n</code></pre></div>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer2</span> <span class=\"o\">=</span> <span class=\"n\">Layer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer2</span><span class=\"o\">.</span><span class=\"n\">add_activation</span><span class=\"p\">(</span><span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer2</span><span class=\"o\">.</span><span class=\"n\">activation</span><span class=\"o\">.</span><span class=\"vm\">__name__</span>\n<span class=\"go\">relu</span>\n</code></pre></div>\n", "parameters": ["self", "activation"], "funcdef": "def"}, {"fullname": "pybann.layers.Layer.add_weights", "modulename": "pybann.layers", "qualname": "Layer.add_weights", "type": "function", "doc": "<p>Add weight matrix for the feed forward, and updated weight matrices\nfor the gradient descent.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>inputNeurons</strong> (int):\nnumber of neurons in the layer</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Layer</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"n\">Layer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">add_weights</span><span class=\"p\">(</span><span class=\"n\">inputNeurons</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">weights</span><span class=\"p\">)</span>\n<span class=\"go\">(4, 8)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">weightsUpdate</span><span class=\"p\">)</span>\n<span class=\"go\">(4, 8)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">weightsUpdateSave</span><span class=\"p\">)</span>\n<span class=\"go\">(4, 8)</span>\n</code></pre></div>\n", "parameters": ["self", "inputNeurons"], "funcdef": "def"}, {"fullname": "pybann.layers.Layer.add_biases", "modulename": "pybann.layers", "qualname": "Layer.add_biases", "type": "function", "doc": "<p>Add biase vector for the feed forward, and updated biase vectors\nfor the gradient descent.</p>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Layer</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"n\">Layer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">add_biases</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"n\">layer1</span><span class=\"o\">.</span><span class=\"n\">biases</span><span class=\"p\">)</span>\n<span class=\"go\">(4,1)</span>\n</code></pre></div>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.model", "modulename": "pybann.model", "qualname": "", "type": "module", "doc": "<p></p>\n"}, {"fullname": "pybann.model.Model", "modulename": "pybann.model", "qualname": "Model", "type": "class", "doc": "<p></p>\n"}, {"fullname": "pybann.model.Model.__init__", "modulename": "pybann.model", "qualname": "Model.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "name"], "funcdef": "def"}, {"fullname": "pybann.model.Model.addInput", "modulename": "pybann.model", "qualname": "Model.addInput", "type": "function", "doc": "<p>Add an input layer to the network model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>neurons</strong> (int):\nnumber of neurons in the input layer</li>\n<li><strong>label</strong> (str (optional)):\nlabel (name) of the layer</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addInput</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Input layer&quot;</span><span class=\"p\">)</span>\n</code></pre></div>\n", "parameters": ["self", "neurons", "label"], "funcdef": "def"}, {"fullname": "pybann.model.Model.addLayer", "modulename": "pybann.model", "qualname": "Model.addLayer", "type": "function", "doc": "<p>Add a layer to the network model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>neurons</strong> (int):\nnumber of neurons in the layer</li>\n<li><strong>activation: str (optional, default</strong> (\"sigmoid)):\nactivation function for the layer</li>\n<li><strong>label</strong> (str (optional)):\nlabel (name) of the layer</li>\n</ul>\n\n<h6 id=\"examples\">Examples</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addInput</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Input layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addLayer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;1st hidden layer&quot;</span><span class=\"p\">)</span>\n</code></pre></div>\n", "parameters": ["self", "neurons", "activation", "label"], "funcdef": "def"}, {"fullname": "pybann.model.Model.build", "modulename": "pybann.model", "qualname": "Model.build", "type": "function", "doc": "<p>Build the network model</p>\n\n<h6 id=\"example\">Example</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addInput</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Input layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addLayer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Hidden layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addLayer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;sigmoid&quot;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Output layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">()</span>\n</code></pre></div>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.model.Model.forward", "modulename": "pybann.model", "qualname": "Model.forward", "type": "function", "doc": "<p>Feed forward the network model</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>inValues</strong> (np.array):\nvector containing the input values for the neural network model</li>\n</ul>\n\n<h6 id=\"example\">Example</h6>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">pybann</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addInput</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Input layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addLayer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;relu&quot;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Hidden layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">addLayer</span><span class=\"p\">(</span><span class=\"n\">neurons</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s2\">&quot;sigmoid&quot;</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s2\">&quot;Output layer&quot;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inData</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">2.</span><span class=\"p\">,</span> <span class=\"mf\">3.</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">network</span><span class=\"o\">.</span><span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">inData</span><span class=\"p\">)</span>\n</code></pre></div>\n", "parameters": ["self", "inValues"], "funcdef": "def"}, {"fullname": "pybann.model.Model.SGD", "modulename": "pybann.model", "qualname": "Model.SGD", "type": "function", "doc": "<p>Train the neural network model</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataset</strong> (list or np.array):\na list of tuples in the form (inValues, outValues)</li>\n<li><strong>batchsize</strong> (int (optional)):\nsize of minibatches for training</li>\n<li><strong>nepoch: int (optional, default</strong> (1000)):\nmaximum number of iterations</li>\n<li><strong>alpha: float (optional, default</strong> (0.05)):\nstep for gradient descent</li>\n<li><strong>momentum: float (optional, default</strong> (0.5)):\nstep for the momentum</li>\n</ul>\n", "parameters": ["self", "dataset", "batchsize", "alpha", "nepoch", "momentum"], "funcdef": "def"}, {"fullname": "pybann.model.Model.PSO", "modulename": "pybann.model", "qualname": "Model.PSO", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, {"fullname": "pybann.model.Model.save", "modulename": "pybann.model", "qualname": "Model.save", "type": "function", "doc": "<p>Save the network model using Pickle</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename: str (default</strong> (network.bann)):\nfilename where to save the network model</li>\n</ul>\n", "parameters": ["self", "filename"], "funcdef": "def"}, {"fullname": "pybann.model.Model.load", "modulename": "pybann.model", "qualname": "Model.load", "type": "function", "doc": "<p>Load a network model using Pickle</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename: str (default</strong> (network.bann)):\nname of the saved network model</li>\n</ul>\n", "parameters": ["self", "filename"], "funcdef": "def"}, {"fullname": "pybann.model.Model.show", "modulename": "pybann.model", "qualname": "Model.show", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}]